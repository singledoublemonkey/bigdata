1. core-site.xml


```xml
<configuration>
        <property>  
                <name>fs.default.name</name>  
                <value>hdfs://yf170:9000/</value>  
                <description>The name of the default file system. A URI whose scheme and authority determine the FileSystem implementation. The uri's s
cheme determines the config property (fs.SCHEME.impl) naming the FileSystem implementation class. The uri's authority is used to determine the host, po
rt, etc. for a filesystem.</description>  

        <property>  
                <name>hadoop.tmp.dir</name>  
                <value>/tmp/hadoop-${user.name}</value>  
                <description></description>  
        </property>
</configuration>
```

2. hdfs-site.xml


```xml
<configuration>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>/web/hadoop/hdfs/name</value>
        </property>
        <property>
                <name>dfs.namenode.checkpoint.dir</name>
                <value>/web/hadoop/hdfs/namesecondary</value>
                <description></description>
        </property>

        <!--hopc.dfs.datanode.data.dir.start-->
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>/web/hadoop/hdfs/data/data2,/web/hadoop/hdfs/data/data3,/web/hadoop/hdfs/data/data4,/web/hadoop/hdfs/data/data5,/web/hadoop/hdfs
/data/data6,/web/hadoop/hdfs/data/data7,/web/hadoop/hdfs/data/data8,/web/hadoop/hdfs/data/data9,/web/hadoop/hdfs/data/data10,/web/hadoop/hdfs/data/data
11,/web/hadoop/hdfs/data/data12</value>
        </property>
        <!--hopc.dfs.datanode.data.dir.end-->

        <property>
                <name>dfs.replication</name>
                <value>3</value>
        </property>
</configuration>
```

3. mapred-site.xml


```xml
<configuration>
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>
        <property>
                <name>mapreduce.map.memory.mb</name>
                <value>8192</value>
        </property>
        <property>
                <name>mapred.child.java.opts</name>
                <value>-Xmx6554m</value>
        </property>
        <property>
                <name>mapreduce.map.java.opts</name>
                <value>-Xmx6554M -XX:-UseGCOverheadLimit</value>
        </property>
        <property>
                <name>mapreduce.reduce.memory.mb</name>
                <value>8192</value>
        </property>
        <property>
                <name>mapreduce.reduce.java.opts</name>
                <value>-Xmx6554M -XX:-UseGCOverheadLimit</value>
        </property>
</configuration>
```

4. yarn-site.xml

配置ResourceManager,NodeManager的通信端口，web监控端口

```xml
<configuration>
        <property>  
                <name>yarn.resourcemanager.resource-tracker.address</name>  
                <value>yf170:8031</value>  
                <description>host is the hostname of the resource manager and  
                        port is the port on which the NodeManagers contact the Resource Manager.  
                </description>  
        </property>  

        <property>  
                <name>yarn.resourcemanager.scheduler.address</name>  
                <value>yf170:8030</value>  
                <description>host is the hostname of the resourcemanager and port is the port  
                        on which the Applications in the cluster talk to the Resource Manager.  
                </description>  
        </property>  

        <property>  
                <name>yarn.resourcemanager.scheduler.class</name>  
                <value>org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>  
                <description>In case you do not want to use the default scheduler</description>  
        </property>  

        <property>  
                <name>yarn.resourcemanager.address</name>  
                <value>yf170:8032</value>  
                <description>the host is the hostname of the ResourceManager and the port is the port on  
                        which the clients can talk to the Resource Manager. </description>  
        </property>  

        <property>  
                <name>yarn.nodemanager.local-dirs</name>  
                <value>${hadoop.tmp.dir}/nodemanager/local</value>  
                <description>the local directories used by the nodemanager</description>  
        </property>  

        <property>  
                <name>yarn.nodemanager.address</name>  
                <value>0.0.0.0:8034</value>  
                <description>the nodemanagers bind to this port</description>  
        </property>   

        <property>  
                <name>yarn.nodemanager.resource.memory-mb</name>  
                <value>65536</value>  
                <description>the amount of memory on the NodeManager in GB</description>  
        </property>  

        <property>  
                <name>yarn.nodemanager.remote-app-log-dir</name>  
                <value>${hadoop.tmp.dir}/nodemanager/remote</value>  
                <description>directory on hdfs where the application logs are moved to </description>  
        </property>  

        <property>  
                <name>yarn.nodemanager.log-dirs</name>  
                <value>${hadoop.tmp.dir}/nodemanager/logs</value>  
                <description>the directories used by Nodemanagers as log directories</description>  
        </property>  

        <property>  
                <name>yarn.nodemanager.aux-services</name>  
                <value>mapreduce_shuffle</value>  
                <description>shuffle service that needs to be set for Map Reduce to run </description>  
        </property>
</configuration>
```
